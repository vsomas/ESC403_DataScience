---
title: "ESC403_SinusPred"
author: "Jerome Sepin"
date: "14 4 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Preparation
```{r Preparation}

# Clean Data
rm(list=ls())

library(keras)
library(tensorflow)
library(ggplot2)
library(dplyr)

# Source Data
source("00_Function_LSTM.r")

```


# Data Generataion
```{r}
# Create Data
days <- 40+10
x <-  c(0:(24*days))
#y <-  sin(x/(24/(2*pi) )) + 0.05*x
y <-  sin(x/(24/(2*pi) )) + 0.005*x^(1.4)
#y <-  sin(x/(24/(2*pi) )) 
plot(x,y,type = "l",xlab = "Days",ylab = "Temperature...")
length(y)
```

# Initiate Hyperparameter
```{r HyperPara, echo=FALSE}
lag = 24
StepPred = 20 # Number of Prediction

```



# Scaling
```{r Scaling, echo=FALSE}
scaledY <- scaling(y = y)
plot(scaledY,type ="l")
```

# Test Data set
```{r TestData, echo=FALSE}


test1 <- scaledY[1:lag] # Untere Ende
test2 <- scaledY[(length(scaledY)-lag-StepPred+1):length(scaledY)] # Obere Ende

scaledY <- scaledY[(lag+1):(length(scaledY)-lag-StepPred)] # Dataset without Test Data

```

# Feature and Label
```{r Feature and Label, echo = FALSE}

# Create Array for Feature and Label
Feature <- FeatLabCreator(lag = lag , y = scaledY)[["Feature"]]
Label <- FeatLabCreator(lag = lag, y = scaledY)[["Label"]]

```

# Split Data into Train and Validation

```{r TrainValidation, echo=FALSE}

# Creating Train and Validation lists:
TrainValid_dat <- TrainValidTest(Feature = Feature, Label = Label, proportion = 0.8)

```

# Model Prediction
```{r ModelPrediction}

model <- keras_model_sequential()

model %>%
  layer_lstm(units = 32,input_shape = c(lag, 1), return_sequences = F ) %>%
    layer_dense(units = 1)

summary(model)


```


# Compile the Neural Network
```{r Compile, echo = FALSE}

model %>%compile(
    loss = 'mean_squared_error',
    optimizer = "adam",
    metrics = c('mean_squared_error')
  )
```

# Train the Neural Network
```{r Train, echo = FALSE}

# train
set.seed(1234)

history_model <- model %>% fit(TrainValid_dat$Feature_Train, TrainValid_dat$Label_Train,
    batch_size = 1, 
    epochs = 100, 
    shuffle = TRUE,
    verbose = TRUE, # 1shows,
    validation_data = list(TrainValid_dat$Feature_Validation,
                           TrainValid_dat$Label_Validation),
    callbacks = list(callback_reduce_lr_on_plateau(monitor = "val_loss",
                                                   factor = 0.1,
                                                   patience = 10),
                     callback_early_stopping(monitor = "val_loss",
                                             min_delta = 0,
                                             patience = 30)
                      )
)
```

# Evaluation of the Nerural Network
```{r Evaluation}


```

```{r}
save_model_hdf5(model, "model.h5")# Whole model saving
history_df <- as.data.frame(history_model)
write.csv(history_df,"history_df", row.names = FALSE)

#load model
model_saved <- load_model_hdf5("model.h5")
model_saved %>% evaluate(dataX_test, dataY_test)
prediction_saved <- model_saved %>% predict(dataX)
```


```{r}
prediction <- model %>% predict(dataX)
prediction_rev_scaled <- prediction*(max(y)-min(y)) + min(y)
plot(prediction_rev_scaled[1:100],type = "l" ,ylim=range(prediction_rev_scaled[1:100], y[(lag+1):(100+lag)]))
lines(y[(lag+1):(100+lag)],type = "l",col = "blue")
legend("center", lty = 1, col =c("black","blue"), legend =c("Prediction", "True"))
```

```{r}
start <- dataX[1,,]
start_arr <- array(start,dim= c(1,lag,1))
hist <- c()

next_pred <- model %>% predict(start_arr)
steps_pred <- 150
for(i in 1:steps_pred){
  next_pred <- model %>% predict(start_arr)
  hist <- c(hist,next_pred)
  start <- c(start[2:length(start)],next_pred)
  start_arr <- array(start,dim= c(1,lag,1))
}

plot(y=hist,x=c((lag+1):(lag+length(hist))), type = "l",ylim = c(-0.5,0.5), xlim = c(1,(lag+steps_pred)))
lines(y=y_scaled[(lag+1):(lag+steps_pred)], x= (lag+1):(lag+steps_pred),col = "red")
lines(y=dataX[1,,], x= 1:lag,col = "blue",lwd = 3)
abline(h = hist[length(hist)] ,lty = 3, col = "gray")
legend("bottom", lty = 1, col =c("black","red","blue"), legend =c("Prediction", "True","Start"))


eval_pred <- sum((hist-y_scaled[(lag+1):(lag+steps_pred)])^2)/length(hist)
```


```{r}

```


