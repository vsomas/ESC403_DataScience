---
title: "ESC403_SinusPred"
author: "Jerome Sepin"
date: "14 4 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Preparation
```{r Preparation}

# Clean Data
rm(list=ls())

library(keras)
library(tensorflow)
tf$random$set_seed(113)
library(ggplot2)
library(dplyr)

# Source Data
source("00_Function_LSTM.r")
source("SinusPrediction.R")

```


# Data Generataion
```{r DataGeneration, echo = FALSE}
# Create Data (deterministic)
days <- 40+10
x <-  c(0:(24*days))
y <-  sin(x/(24/(2*pi) )) + 0.005*x^(1.4) #+ rnorm(length(x), mean = 0, sd = 0.1)
plot(x,y,type = "l",xlab = "Days",ylab = "Temperature...")
length(y)
```

# Initiate Hyperparameter-Grid
```{r HyperPara, echo=FALSE}
StepPred = 20 # Number of Prediction
lag_grid         <- c(24, 38, 52, 66)
lstm1_units_grid <- c(12, 24, 48, 96)
```

# Scaling
```{r Scaling, echo=FALSE}
scaledY <- scaling(y = y)
plot(scaledY,type ="l")
```

# Run the Neural Netowrk
```{r,eval = F}
parameter_grid <- expand_grid(lag_grid, lstm1_units_grid)
best_model_MSE <- Inf
df_results <- c()
df_history <- c()

for(i in 1:nrow(parameter_grid)){
  res <- LSTM_sinus_prediction(lag=as.integer(parameter_grid[i,1]), StepPred,
                               lstm1_units=as.integer(parameter_grid[i,2]),
                               scaledY = scaledY, y=y,ep=100 )
  #save best model:
  if( sum(res$results[c("MSE1","MSE2")]) < best_model_MSE){
    best_model_MSE <- sum(res$results[c("MSE1","MSE2")]) 
    save_model_hdf5(res$model, "model_sinus.h5")
  }
  
  #save results
  df_results  <- rbind(df_results, res$results)
  write.csv(data.frame(df_results ),"df_sinus_results.csv", row.names = FALSE)
  
  #save results
  df_history  <- rbind(df_history, res$history)
  write.csv(data.frame(df_history ),"df_sinus_history.csv", row.names = FALSE)
  
  #show progress
  print(df_results)
} 
```


# Load values & Model
```{r Plotting, echo = FALSE}
#get best model & parameters
model_saved<-load_model_hdf5("model_sinus.h5")# load whole model
df_results <- read.csv("df_sinus_results.csv")# load results of the neural networks
best_model_index <- which.min(rowSums(df_results[,c("MSE1","MSE2")]))
best_lag <- df_results[best_model_index, c("lag")]
```


```{r}
# visualization of results
df_results <- tidyr::gather(df_results,key = "key",value = "MSE", -c(lag,StepPred,lstm1_units))
df_results <- df_results[order(df_results$lstm1_units),]

df_results$lstm1_units <- factor(df_results$lstm1_units, levels = c(6,12,24,48,96,192,384),
labels = paste0("lstm unit = ",c(6,12,24,48,96,192,384))
) 

ggplot(data = df_results, aes(x=lag,y=log(MSE),col = as.factor(key) ))+
  geom_point(position=position_dodge(5))+
  geom_smooth(se = FALSE, method = 'loess')+
  facet_wrap(~lstm1_units)+
  theme_bw()+
  scale_color_manual("",values=c("darkred","darkblue"))+
  theme(legend.position="top")

```







# Plotting the sinusfunction of the best model:

```{r Plotting, echo = FALSE}
StepPred <-20

  # Lower end
test_lwrEnd <- scaledY[1:(best_lag+StepPred)]                         # scaled test
pred_lwrEnd <- pred_steps(model = model_saved, 
                          start = array(test_lwrEnd[1:best_lag],
                                        dim = c(1,best_lag,1)),
                          StepPred = StepPred)                        # Prediction
true_lwrEnd <- test_lwrEnd[(best_lag+1):length(test_lwrEnd)]               # True
pred_lwrEnd <- pred_lwrEnd*(max(y)-min(y)) + min(y)                   # Back scaling
true_lwrEnd <- true_lwrEnd*(max(y)-min(y)) + min(y)                   # Back scaling


  # Upper end
test_uprEnd <- scaledY[(length(scaledY)-best_lag-StepPred+1):length(scaledY)]                    # scaled test
pred_uprEnd <- pred_steps(model = model_saved, start=test_uprEnd[1:best_lag], StepPred=StepPred) # Prediction
true_uprEnd <- test_uprEnd[(best_lag+1):length(test_uprEnd)]                                     # True
pred_uprEnd <- pred_uprEnd*(max(y)-min(y)) + min(y)                                         # Back scaling
true_uprEnd <- true_uprEnd*(max(y)-min(y)) + min(y)                                         # Back scaling

df_prediction <- data.frame(true_lwrEnd,pred_lwrEnd, true_uprEnd, pred_uprEnd)
df_prediction$x <- 1:nrow(df_prediction)
df_prediction <- tidyr::gather(df_prediction, key = "key", value = "value",-c(x))
df_prediction <- cbind(df_prediction, matrix(unlist(strsplit(df_prediction$key,"_")),ncol = 2,byrow = T))
df_prediction <- dplyr::select(df_prediction,-c(key))
colnames(df_prediction) <- c("x","y","True","End")

ggplot(data = df_prediction, aes(x=x,y=y,col = as.factor(True) ))+
  geom_line()+
  labs(title = "",y = "",
       x="")+
  facet_wrap(~End,scales = "free")+
  theme_bw()+
  scale_color_manual("",values=c("darkred","darkblue"))+
  theme(legend.position="top")
```



```{r}
library(tram)
df_results$lstm1_units <- as.integer(stringr::str_replace(df_results$lstm1_units,"lstm unit = ",""))
model1 <- tram::BoxCox(data = df_results, MSE~lag+lstm1_units)
summary(model1)
```
